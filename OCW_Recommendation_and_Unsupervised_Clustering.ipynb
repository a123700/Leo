{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a123700/Leo/blob/master/OCW_Recommendation_and_Unsupervised_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQW2SL79QSj"
      },
      "outputs": [],
      "source": [
        "%reset -f"
      ],
      "id": "9zQW2SL79QSj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-9DOxdj3NlF"
      },
      "source": [
        "#Load Data"
      ],
      "id": "k-9DOxdj3NlF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJVbXY_f-LUQ"
      },
      "outputs": [],
      "source": [
        "api_token = {\"username\":\"srhgccc\",\"key\":\"41c36ccc1ee7bc07f70e459ccbf7df7c\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        " \n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    os.makedirs(\"/root/.kaggle\")\n",
        " \n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        " \n",
        "if not os.path.exists(\"/kaggle\"):\n",
        "    os.makedirs(\"/kaggle\")\n",
        "os.chdir('/kaggle')"
      ],
      "id": "IJVbXY_f-LUQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SP4ihTH-ODo"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d srhgccc/ocw-dataset"
      ],
      "id": "3SP4ihTH-ODo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDcwA5D9_34n"
      },
      "outputs": [],
      "source": [
        "!unzip ocw-dataset.zip"
      ],
      "id": "YDcwA5D9_34n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH2inIBO9QSl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "sH2inIBO9QSl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-BOFaDo9QSo"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('NewOCW.csv')\n",
        "dataset = dataset.dropna()\n",
        "dataset['client_id'] = dataset['client_id'].astype('str')\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "dateset = dataset.sort_values(by='date', ascending=True, inplace=True)\n",
        "dataset = dataset.drop(columns=['page', 'links'])"
      ],
      "id": "_-BOFaDo9QSo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbbudbBnCu1y"
      },
      "outputs": [],
      "source": [
        "print(dataset.shape)"
      ],
      "id": "wbbudbBnCu1y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQzkS_sCcoXM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "dataset['time_delta'] = (max(dataset['date']) - dataset['date'])\n",
        "dataset['time_delta'] = list(map(lambda x: x.days, dataset['time_delta']))"
      ],
      "id": "eQzkS_sCcoXM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVNdeb2IY_CW"
      },
      "outputs": [],
      "source": [
        "r = 0.75\n",
        "dataset['user_score'] = r**dataset['time_delta']"
      ],
      "id": "YVNdeb2IY_CW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2dTMx_FWoCV"
      },
      "outputs": [],
      "source": [
        "dataset.head(2)"
      ],
      "id": "L2dTMx_FWoCV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFUGqugKAyp3"
      },
      "outputs": [],
      "source": [
        "user_mappings = {k:v for v, k in enumerate(dataset['client_id'].unique())}\n",
        "dataset['client_id'] = dataset['client_id'].map(user_mappings)"
      ],
      "id": "GFUGqugKAyp3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHXPmcK03AvA"
      },
      "source": [
        "#Data Preprocessing"
      ],
      "id": "sHXPmcK03AvA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFdyg56oXlff"
      },
      "outputs": [],
      "source": [
        "dataset['hour'] = list(map(lambda x: str(x)[11:13], dataset['date']))\n",
        "cc = dataset.groupby('client_id')['title'].nunique()\n",
        "cc = pd.DataFrame(cc)\n",
        "cc = cc.rename(columns={'title': 'number'})\n",
        "dataset = pd.merge(dataset, cc, on=\"client_id\")"
      ],
      "id": "bFdyg56oXlff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAn2XSe7_jPO"
      },
      "outputs": [],
      "source": [
        "dataset.head(2)"
      ],
      "id": "IAn2XSe7_jPO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcB6K9QeDknw"
      },
      "source": [
        "# Input Output Split"
      ],
      "id": "LcB6K9QeDknw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6NCehLEYx13"
      },
      "outputs": [],
      "source": [
        "# Use previous x-n behaviors to predict last n behaviors\n",
        "from tqdm import tqdm\n",
        "\n",
        "X = pd.DataFrame()\n",
        "Y = pd.DataFrame()\n",
        "n = 1\n",
        "person = []\n",
        "for i in tqdm(range(max(dataset['client_id'])+1)):\n",
        "  temp = dataset[dataset['client_id'] == i]\n",
        "  if temp.shape[0] < n+1:\n",
        "    person.append(i)\n",
        "    continue\n",
        "  X = pd.concat([X, temp.iloc[:-n, :]], axis = 0)  #rbind\n",
        "  Y = pd.concat([Y, temp.iloc[-n:, :]], axis = 0)  \n",
        "del temp"
      ],
      "id": "E6NCehLEYx13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AKVS4vMbiOz"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "id": "0AKVS4vMbiOz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZrbeYBkByRq"
      },
      "source": [
        "# Train Test Split"
      ],
      "id": "LZrbeYBkByRq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvYchVXsfqTk"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "import random\n",
        "\n",
        "random.seed(1234)\n",
        "\n",
        "id = list(X['client_id'].unique())\n",
        "id_train = sample(list(id), int(len(id)*0.75))\n",
        "id_test = []\n",
        "for i in id:\n",
        "  if i not in id_train:\n",
        "    id_test.append(i)"
      ],
      "id": "YvYchVXsfqTk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGLWsUZkjE_R"
      },
      "outputs": [],
      "source": [
        "print(len(id_train))\n",
        "print(len(id_test))"
      ],
      "id": "VGLWsUZkjE_R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7g6i73yjVup"
      },
      "outputs": [],
      "source": [
        "x_train = X[X['client_id'].isin(id_train)]\n",
        "x_test = X[X['client_id'].isin(id_test)]\n",
        "\n",
        "y_train = Y[Y['client_id'].isin(id_train)]\n",
        "y_test = Y[Y['client_id'].isin(id_test)]"
      ],
      "id": "Q7g6i73yjVup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVt1grDcqAGK"
      },
      "outputs": [],
      "source": [
        "mx_train = pd.crosstab(x_train.client_id, x_train.title, normalize='index', values = x_train.user_score, aggfunc = np.sum)\n",
        "class_train = mx_train.columns\n",
        "mx_train = np.array(mx_train)\n",
        "\n",
        "mx_test = pd.crosstab(x_test.client_id, x_test.title, normalize='index', values = x_test.user_score, aggfunc = np.sum)\n",
        "mx_test = np.array(mx_test)\n",
        "\n",
        "mx_train1 = pd.crosstab(x_train.client_id, x_train.hour, normalize='index')\n",
        "mx_train1 = np.array(mx_train1)\n",
        "\n",
        "mx_test1 = pd.crosstab(x_test.client_id, x_test.hour, normalize='index')\n",
        "mx_test1 = np.array(mx_test1)"
      ],
      "id": "OVt1grDcqAGK"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import manifold\n",
        "X_tsne = manifold.TSNE(n_components=2, init='pca', random_state=5, verbose=1).fit_transform(mx_train)"
      ],
      "metadata": {
        "id": "TSgDPL-lKVvq"
      },
      "id": "TSgDPL-lKVvq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Visualization\n",
        "x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n",
        "X_norm = (X_tsne - x_min) / (x_max - x_min)  #Normalize\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(X_norm.shape[0]):\n",
        "    plt.text(X_norm[i, 0], X_norm[i, 1], s = i, size = 7)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GO2tIW_KhFd"
      },
      "id": "6GO2tIW_KhFd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maCaO-krGzYJ"
      },
      "source": [
        "# Test data"
      ],
      "id": "maCaO-krGzYJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KIzlK1qmcRc"
      },
      "outputs": [],
      "source": [
        "my_train = pd.crosstab(y_train.client_id, y_train.title, normalize='index')\n",
        "classy_train = list(my_train.columns)\n",
        "my_train = np.array(my_train)\n",
        "\n",
        "my_test = pd.crosstab(y_test.client_id, y_test.title, normalize='index')\n",
        "classy_test = list(my_test.columns)\n",
        "my_test = np.array(my_test)"
      ],
      "id": "4KIzlK1qmcRc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBYuXrDd22u_"
      },
      "source": [
        "#Model Building"
      ],
      "id": "iBYuXrDd22u_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-fSXfxEnRfp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Reshape, BatchNormalization, LSTM, Reshape\n",
        "from keras.models import Model\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "id": "S-fSXfxEnRfp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17hXHzdKnhN2"
      },
      "outputs": [],
      "source": [
        "print(mx_train.shape)\n",
        "print(mx_test.shape)\n",
        "print(mx_train1.shape)\n",
        "print(mx_test1.shape)\n",
        "print(my_train.shape)\n",
        "print(my_test.shape)"
      ],
      "id": "17hXHzdKnhN2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SADHD0kznX59"
      },
      "outputs": [],
      "source": [
        "def model_build():\n",
        "  # Input Layer\n",
        "  user_input = Input(shape=(mx_train.shape[1], ), name = \"User-Input\")\n",
        "  user_vec = Dense(32, activation='relu')(user_input)\n",
        "\n",
        "  pattern_input = Input(shape=(mx_train1.shape[1], ), name = \"Pattern-Input\")\n",
        "  pattern_vec = Dense(8, activation='relu')(pattern_input)\n",
        "\n",
        "  # Concatenate Features\n",
        "  conc = Concatenate()([user_vec, pattern_vec])\n",
        "\n",
        "  # Fully Connected Layer\n",
        "  fc2 = BatchNormalization()(conc)\n",
        "  fc3 = Dense(32, activation='relu')(fc2)\n",
        "  fc4 = BatchNormalization()(fc3)\n",
        "  fc5 = Dense(128, activation='relu')(fc4)\n",
        "  fc6 = BatchNormalization()(fc5)\n",
        "\n",
        "  # Output Layer\n",
        "  out = Dense(my_train.shape[1], activation = 'softmax')(fc6)\n",
        "\n",
        "  model = Model(inputs = [user_input, pattern_input], outputs = out)\n",
        "  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "id": "SADHD0kznX59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v6y8AOGqocg"
      },
      "outputs": [],
      "source": [
        "model = model_build()\n",
        "model.summary()"
      ],
      "id": "4v6y8AOGqocg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rA9Elwoqp5w"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, show_shapes=True)"
      ],
      "id": "7rA9Elwoqp5w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4pmPWyoBsqS"
      },
      "source": [
        "#Model Training"
      ],
      "id": "-4pmPWyoBsqS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8rs_3peqtzz"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "history = model.fit([mx_train, mx_train1], my_train, epochs=100, verbose=True, batch_size = 128, callbacks=callbacks, validation_split = 0.15)"
      ],
      "id": "-8rs_3peqtzz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F_FxLKLSpsK"
      },
      "source": [
        "#Performace Review"
      ],
      "id": "-F_FxLKLSpsK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt1Ep4xmrX5k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "id": "gt1Ep4xmrX5k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_H0-Zp2G2U-"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "id": "a_H0-Zp2G2U-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_KvKPD-rbqL"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict([mx_test, mx_test1])\n",
        "pd.DataFrame(predictions, columns=classy_train)"
      ],
      "id": "7_KvKPD-rbqL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tntz9C1eB7sM"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(predictions, axis = 1)"
      ],
      "id": "Tntz9C1eB7sM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8lAkUX6xz1N"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for i in predictions:\n",
        "  result.append(classy_train[i])"
      ],
      "id": "_8lAkUX6xz1N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5uzAytGGVJP"
      },
      "outputs": [],
      "source": [
        "compare = pd.DataFrame()\n",
        "compare['Predict'] = result\n",
        "compare['Real'] = list(y_test['title'])\n",
        "compare"
      ],
      "id": "O5uzAytGGVJP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuAb9gy51kLQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"預測準確率 %.2f\"%(accuracy_score(result, list(y_test['title']))))"
      ],
      "id": "nuAb9gy51kLQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAHoqpn4CvYY"
      },
      "source": [
        "# LSTM model with Embedding Structure"
      ],
      "id": "TAHoqpn4CvYY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvzjKc6bCuMf"
      },
      "outputs": [],
      "source": [
        "!pip install -q zhon"
      ],
      "id": "IvzjKc6bCuMf"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PlhSpt1FW2yL"
      },
      "id": "PlhSpt1FW2yL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX6OzHmFHe0M"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('NewOCW.csv')\n",
        "dataset = dataset.dropna()\n",
        "dataset['client_id'] = dataset['client_id'].astype('str')\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "dateset = dataset.sort_values(by='date', ascending=True, inplace=True)\n",
        "dataset = dataset.drop(columns=['page', 'links'])"
      ],
      "id": "fX6OzHmFHe0M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5G-nZRrJToQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from zhon.hanzi import punctuation\n",
        "\n",
        "user_mappings = {k:v for v, k in enumerate(dataset['client_id'].unique())}\n",
        "dataset['client_id'] = dataset['client_id'].map(user_mappings)\n",
        "\n",
        "punctuation_str = punctuation\n",
        "dataset['title_tokenized'] = list(map(lambda x: re.sub(\"[%s]+\" %punctuation_str, \"\", x), dataset['title']))\n",
        "class_mappings = {k:v for v, k in enumerate(dataset['title_tokenized'].unique())}\n",
        "dataset['title_tokenized'] = dataset['title_tokenized'].map(class_mappings)"
      ],
      "id": "_5G-nZRrJToQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRuFy_nZ-eOC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "le=LabelEncoder()\n",
        "dataset['title_encoded'] = le.fit_transform(dataset['title'])"
      ],
      "id": "HRuFy_nZ-eOC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB-FvF4zlh_A"
      },
      "outputs": [],
      "source": [
        "dataset.head(2)"
      ],
      "id": "dB-FvF4zlh_A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcQxirz0I8mw"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "id = set(dataset['client_id'])\n",
        "id_train = sample(id, int(len(id)*0.75))\n",
        "id_test = []\n",
        "for i in id:\n",
        "  if i not in id_train:\n",
        "    id_test.append(i)\n",
        "\n",
        "print(len(id_train))\n",
        "print(len(id_test))"
      ],
      "id": "gcQxirz0I8mw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSQuFflVLP5P"
      },
      "outputs": [],
      "source": [
        "train = dataset[dataset['client_id'].isin(id_train)]\n",
        "test = dataset[dataset['client_id'].isin(id_test)]"
      ],
      "id": "OSQuFflVLP5P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2oS0q40Lmaj"
      },
      "outputs": [],
      "source": [
        "# Use previous x-n behaviors to predict last n behaviors\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "m = 75\n",
        "for i in tqdm(set(train['client_id'])):\n",
        "  temp = train[train['client_id'] == i]['title_tokenized'].values\n",
        "  temp1 = train[train['client_id'] == i]['title_encoded'].values\n",
        "  if len(temp) < m:\n",
        "    continue\n",
        "  temp = temp.reshape(-1, 1)\n",
        "  temp1 = temp1.reshape(-1, 1)\n",
        "  for j in range(m, temp.shape[0]):  \n",
        "    X_train.append(temp[j-m:j, 0])\n",
        "    y_train.append(temp1[j, 0].astype('float'))\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in tqdm(set(test['client_id'])):\n",
        "  temp = test[test['client_id'] == i]['title_tokenized'].values\n",
        "  temp1 = test[test['client_id'] == i]['title_encoded'].values\n",
        "  if len(temp) < m:\n",
        "    continue\n",
        "  temp = temp.reshape(-1, 1)\n",
        "  temp1 = temp1.reshape(-1, 1)\n",
        "  for j in range(m, temp.shape[0]):  \n",
        "    X_test.append(temp[j-m:j, 0])\n",
        "    y_test.append(temp1[j, 0].astype('float'))\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)"
      ],
      "id": "F2oS0q40Lmaj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNDFaQrGSROR"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "JNDFaQrGSROR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIYot6LU6T-w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Reshape, BatchNormalization, LSTM, Reshape, Bidirectional, TimeDistributed\n",
        "from keras.models import Model\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "id": "VIYot6LU6T-w"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = len(set(y_train))\n",
        "\n",
        "class_input = Input(shape=(X_train.shape[1], ), name = \"Class-Input\")\n",
        "embedding_output = Embedding(input_dim = X_train.shape[1]+1, \n",
        "                                output_dim = embedding_size, \n",
        "                                name = \"Behavior-Embedding\")(class_input)\n",
        "embedding = Model(class_input, embedding_output, name = 'Encoder')\n",
        "embedding.summary()"
      ],
      "metadata": {
        "id": "5Pglbltc4ts4"
      },
      "id": "5Pglbltc4ts4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = Input(shape=(m, embedding_size, ), name=\"decoder_input\")\n",
        "# LSTM Layer \n",
        "lstm = LSTM(units = 32, return_sequences = True)(decoder_input)\n",
        "bn = BatchNormalization()(lstm)\n",
        "lstm_1 = LSTM(units = 16, return_sequences = True)(bn)\n",
        "bn1 = BatchNormalization()(lstm_1)\n",
        "lstm_2 = LSTM(units = 8, return_sequences = False)(bn1)\n",
        "bn2 = BatchNormalization()(lstm_2)\n",
        "\n",
        "# Fully Connected Layer\n",
        "fc3 = Dense(32, activation='relu')(bn2)\n",
        "fc4 = BatchNormalization()(fc3)\n",
        "fc5 = Dense(128, activation='relu')(fc4)\n",
        "fc6 = BatchNormalization()(fc5)\n",
        "\n",
        "# Output Layer\n",
        "out = Dense(len(set(y_train)), activation = 'softmax')(fc6)\n",
        "\n",
        "decoder = Model(decoder_input, out, name = 'Decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "4OH3JR-n5EhR"
      },
      "id": "4OH3JR-n5EhR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = Input(shape=(X_train.shape[1], ))\n",
        "embedding_output = embedding(model_input)\n",
        "output = decoder(embedding_output)\n",
        "\n",
        "model1 = Model(model_input, output)\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "B-85Jrnl52BW"
      },
      "id": "B-85Jrnl52BW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "97UYCiKqYELU"
      },
      "id": "97UYCiKqYELU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv_TdvkV6eEf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model1, show_shapes=True)"
      ],
      "id": "zv_TdvkV6eEf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge2u7E0_6mkh"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "history = model1.fit(X_train, y_train, epochs=100, verbose=True, batch_size = 512, callbacks=callbacks, validation_split = 0.15)"
      ],
      "id": "ge2u7E0_6mkh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OAu-ZHt27Z1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "id": "1OAu-ZHt27Z1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4cTW_XS2881"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "id": "p4cTW_XS2881"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFLRzDIG3I6R"
      },
      "outputs": [],
      "source": [
        "predictions = model1.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "result = le.inverse_transform(predictions)"
      ],
      "id": "cFLRzDIG3I6R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PhLEwXF37TO"
      },
      "outputs": [],
      "source": [
        "compare = pd.DataFrame()\n",
        "compare['Predict'] = result\n",
        "compare['Real'] = le.inverse_transform(y_test.astype('int'))\n",
        "compare"
      ],
      "id": "_PhLEwXF37TO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpzhqHyB4ssV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Prediction Accuracy %.2f\"%(accuracy_score(result, le.inverse_transform(y_test.astype('int')))))"
      ],
      "id": "LpzhqHyB4ssV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer model with position encoding"
      ],
      "metadata": {
        "id": "41xxMmgYX0-L"
      },
      "id": "41xxMmgYX0-L"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "DZFS1pYlY4-n"
      },
      "id": "DZFS1pYlY4-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1PWrFzGZ8hj"
      },
      "outputs": [],
      "source": [
        "!pip install -q zhon"
      ],
      "id": "c1PWrFzGZ8hj"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nQCh6MTEZ8hl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nQCh6MTEZ8hl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zfcMANgZ8hl"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('NewOCW.csv')\n",
        "dataset = dataset.dropna()\n",
        "dataset['client_id'] = dataset['client_id'].astype('str')\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "dateset = dataset.sort_values(by='date', ascending=True, inplace=True)\n",
        "dataset = dataset.drop(columns=['page', 'links'])"
      ],
      "id": "8zfcMANgZ8hl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBLxjVU-Z8hl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from zhon.hanzi import punctuation\n",
        "\n",
        "user_mappings = {k:v for v, k in enumerate(dataset['client_id'].unique())}\n",
        "dataset['client_id'] = dataset['client_id'].map(user_mappings)\n",
        "\n",
        "punctuation_str = punctuation\n",
        "dataset['title_tokenized'] = list(map(lambda x: re.sub(\"[%s]+\" %punctuation_str, \"\", x), dataset['title']))\n",
        "class_mappings = {k:v for v, k in enumerate(dataset['title_tokenized'].unique())}\n",
        "dataset['title_tokenized'] = dataset['title_tokenized'].map(class_mappings)"
      ],
      "id": "IBLxjVU-Z8hl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6KAAVWyZ8hm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "le=LabelEncoder()\n",
        "dataset['title_encoded'] = le.fit_transform(dataset['title'])"
      ],
      "id": "k6KAAVWyZ8hm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ar3sYN-Z8hm"
      },
      "outputs": [],
      "source": [
        "dataset.head(2)"
      ],
      "id": "6Ar3sYN-Z8hm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgfYdZJ6Z8hm"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "id = set(dataset['client_id'])\n",
        "id_train = sample(id, int(len(id)*0.75))\n",
        "id_test = []\n",
        "for i in id:\n",
        "  if i not in id_train:\n",
        "    id_test.append(i)\n",
        "\n",
        "print(len(id_train))\n",
        "print(len(id_test))"
      ],
      "id": "MgfYdZJ6Z8hm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiKPvIcQZ8hm"
      },
      "outputs": [],
      "source": [
        "train = dataset[dataset['client_id'].isin(id_train)]\n",
        "test = dataset[dataset['client_id'].isin(id_test)]"
      ],
      "id": "IiKPvIcQZ8hm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXsf3zW7Z8hn"
      },
      "outputs": [],
      "source": [
        "# Use previous x-n behaviors to predict last n behaviors\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "m = 75\n",
        "for i in tqdm(set(train['client_id'])):\n",
        "  temp = train[train['client_id'] == i]['title_tokenized'].values\n",
        "  temp1 = train[train['client_id'] == i]['title_encoded'].values\n",
        "  if len(temp) < m:\n",
        "    continue\n",
        "  temp = temp.reshape(-1, 1)\n",
        "  temp1 = temp1.reshape(-1, 1)\n",
        "  for j in range(m, temp.shape[0]):  \n",
        "    X_train.append(temp[j-m:j, 0])\n",
        "    y_train.append(temp1[j, 0].astype('float'))\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in tqdm(set(test['client_id'])):\n",
        "  temp = test[test['client_id'] == i]['title_tokenized'].values\n",
        "  temp1 = test[test['client_id'] == i]['title_encoded'].values\n",
        "  if len(temp) < m:\n",
        "    continue\n",
        "  temp = temp.reshape(-1, 1)\n",
        "  temp1 = temp1.reshape(-1, 1)\n",
        "  for j in range(m, temp.shape[0]):  \n",
        "    X_test.append(temp[j-m:j, 0])\n",
        "    y_test.append(temp1[j, 0].astype('float'))\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)"
      ],
      "id": "XXsf3zW7Z8hn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HHXPSK3Z8ho"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "9HHXPSK3Z8ho"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "18aZBOoaX67j"
      },
      "id": "18aZBOoaX67j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "Qj3WNyhcX9rZ"
      },
      "id": "Qj3WNyhcX9rZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = len(set(y_train))  # Embedding size for each token\n",
        "num_heads = 10  # Number of attention heads\n",
        "ff_dim = 256  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(X_train.shape[1],))\n",
        "embedding_layer = TokenAndPositionEmbedding(X_train.shape[1], len(set(y_train)), embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(len(set(y_train))*2, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "outputs = layers.Dense(len(set(y_train)), activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "S3zm3i_bX-OD"
      },
      "id": "S3zm3i_bX-OD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_8SUCjvQYMdZ"
      },
      "id": "_8SUCjvQYMdZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "red_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=0,factor=0.1)\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, verbose=True, batch_size = 512, callbacks=[red_lr, callbacks], validation_split = 0.15)"
      ],
      "metadata": {
        "id": "akzLldPYYNCx"
      },
      "id": "akzLldPYYNCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrqT7I1OarwY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "id": "ZrqT7I1OarwY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21fzblxXarwZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "id": "21fzblxXarwZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLAtlROTarwZ"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "result = le.inverse_transform(predictions)"
      ],
      "id": "xLAtlROTarwZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOFLvovkarwZ"
      },
      "outputs": [],
      "source": [
        "compare = pd.DataFrame()\n",
        "compare['Predict'] = result\n",
        "compare['Real'] = le.inverse_transform(y_test.astype('int'))\n",
        "compare"
      ],
      "id": "pOFLvovkarwZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUH_zscCarwZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Prediction Accuracy %.2f\"%(accuracy_score(result, le.inverse_transform(y_test.astype('int')))))"
      ],
      "id": "fUH_zscCarwZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkyEdlKqDzIB"
      },
      "source": [
        "# Autoencoder for Segmentation"
      ],
      "id": "DkyEdlKqDzIB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nik9qW4SD_Xp"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('NewOCW.csv')\n",
        "dataset = dataset.dropna()\n",
        "dataset['client_id'] = dataset['client_id'].astype('str')\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "dateset = dataset.sort_values(by='date', ascending=True, inplace=True)\n",
        "dataset = dataset.drop(columns=['page', 'links'])"
      ],
      "id": "Nik9qW4SD_Xp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wXzdeNFFLfN"
      },
      "outputs": [],
      "source": [
        "user_mappings = {k:v for v, k in enumerate(dataset['client_id'].unique())}\n",
        "dataset['client_id'] = dataset['client_id'].map(user_mappings)"
      ],
      "id": "4wXzdeNFFLfN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeTSoFoEFR4D"
      },
      "outputs": [],
      "source": [
        "dataset['hour'] = list(map(lambda x: str(x)[11:13], dataset['date']))\n",
        "cc = dataset.groupby('client_id')['title'].nunique()\n",
        "cc = pd.DataFrame(cc)\n",
        "cc = cc.rename(columns={'title': 'number'})\n",
        "dataset = pd.merge(dataset, cc, on=\"client_id\")\n",
        "del cc"
      ],
      "id": "QeTSoFoEFR4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu6P2BDbaLTa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "dataset['time_delta'] = (max(dataset['date']) - dataset['date'])\n",
        "dataset['time_delta'] = list(map(lambda x: x.days, dataset['time_delta']))"
      ],
      "id": "Hu6P2BDbaLTa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTLNdBlfaNGS"
      },
      "outputs": [],
      "source": [
        "r = 0.8\n",
        "dataset['user_score'] = r**dataset['time_delta']"
      ],
      "id": "NTLNdBlfaNGS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTnImdUCD2zu"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "id = list(dataset['client_id'].unique())\n",
        "id_train = sample(list(id), int(len(id)*0.75))\n",
        "id_test = []\n",
        "for i in id:\n",
        "  if i not in id_train:\n",
        "    id_test.append(i)"
      ],
      "id": "mTnImdUCD2zu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUvRw3WGEE3M"
      },
      "outputs": [],
      "source": [
        "x_train = dataset[dataset['client_id'].isin(id_train)]\n",
        "x_test = dataset[dataset['client_id'].isin(id_test)]"
      ],
      "id": "mUvRw3WGEE3M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blKO1QHNEL_A"
      },
      "outputs": [],
      "source": [
        "mx_train = pd.crosstab(x_train.client_id, x_train.title, normalize='index', values = x_train.user_score, aggfunc = np.sum)\n",
        "mx_train = np.array(mx_train)\n",
        "\n",
        "mx_test = pd.crosstab(x_test.client_id, x_test.title, normalize='index', values = x_test.user_score, aggfunc = np.sum)\n",
        "mx_test = np.array(mx_test)"
      ],
      "id": "blKO1QHNEL_A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrrfyu9WERPD"
      },
      "outputs": [],
      "source": [
        "mx_train1 = pd.crosstab(x_train.client_id, x_train.hour, normalize='index')\n",
        "mx_train1 = np.array(mx_train1)\n",
        "\n",
        "mx_test1 = pd.crosstab(x_test.client_id, x_test.hour, normalize='index')\n",
        "mx_test1 = np.array(mx_test1)"
      ],
      "id": "zrrfyu9WERPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HF9GnSAES6u"
      },
      "outputs": [],
      "source": [
        "train = np.concatenate([mx_train, mx_train1], axis = 1)\n",
        "test = np.concatenate([mx_test, mx_test1], axis = 1)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "id": "3HF9GnSAES6u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzWxI2wYFiwc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Reshape, BatchNormalization, LSTM, Reshape\n",
        "from keras.models import Model\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "id": "KzWxI2wYFiwc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCu0UtpGFyfh"
      },
      "outputs": [],
      "source": [
        "encoding_dim = 3\n",
        "\n",
        "user_input = Input(shape=(train.shape[1], ), name = \"User-Input\")\n",
        "x = Dense(128, activation='relu')(user_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(4, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "encoded_output = Dense(encoding_dim, activation='relu')(x)"
      ],
      "id": "VCu0UtpGFyfh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkmtvR68KAwD"
      },
      "outputs": [],
      "source": [
        "encoder = Model(user_input, encoded_output, name = 'Encoder')\n",
        "encoder.summary()"
      ],
      "id": "QkmtvR68KAwD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBwZ5kE0Krun"
      },
      "outputs": [],
      "source": [
        "decoder_input = Input(shape=(encoding_dim, ), name=\"decoder_input\")\n",
        "x = Dense(4, activation='relu')(decoder_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded_output = Dense(train.shape[1], activation='relu')(x)"
      ],
      "id": "xBwZ5kE0Krun"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWr0HX3wLEHu"
      },
      "outputs": [],
      "source": [
        "decoder = Model(decoder_input, decoded_output, name = 'Decoder')\n",
        "decoder.summary()"
      ],
      "id": "GWr0HX3wLEHu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59mjpN_OLJ4q"
      },
      "outputs": [],
      "source": [
        "ae_input = Input(shape=(train.shape[1], ), name=\"AE_input\")\n",
        "ae_encoder_output = encoder(ae_input)\n",
        "ae_decoder_output = decoder(ae_encoder_output)"
      ],
      "id": "59mjpN_OLJ4q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcRDC6DKLwye"
      },
      "outputs": [],
      "source": [
        "ae = Model(ae_input, ae_decoder_output, name=\"AE\")\n",
        "ae.summary()"
      ],
      "id": "CcRDC6DKLwye"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0dAw53GbIrl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(ae, show_shapes=True)"
      ],
      "id": "o0dAw53GbIrl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgcoszYuL4Mb"
      },
      "outputs": [],
      "source": [
        "ae.compile(optimizer='adam', loss='mse', metrics = ['mae'])"
      ],
      "id": "zgcoszYuL4Mb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdSFyaD6MEOP"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "\n",
        "History = ae.fit(train, train, epochs=100, batch_size=128, shuffle=True, validation_split = 0.1, callbacks=callbacks)"
      ],
      "id": "GdSFyaD6MEOP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAb29KIPM6jg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(History.history['loss'])\n",
        "plt.plot(History.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "id": "OAb29KIPM6jg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH0vjNBjgb3k"
      },
      "outputs": [],
      "source": [
        "ae.evaluate(test, test)"
      ],
      "id": "cH0vjNBjgb3k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goSmuwGYM9uK"
      },
      "outputs": [],
      "source": [
        "user = np.concatenate([train, test], axis = 0)\n",
        "encoded_data = encoder.predict(user)\n",
        "decoded_data = decoder.predict(encoded_data)"
      ],
      "id": "goSmuwGYM9uK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WNJr1ttNRgn"
      },
      "outputs": [],
      "source": [
        "columns_names = []\n",
        "for i in range(encoding_dim):\n",
        "  columns_names.append('dim_'+str(i+1))\n",
        "result = pd.DataFrame(encoded_data, columns = columns_names)"
      ],
      "id": "5WNJr1ttNRgn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-aqZR21d8RB"
      },
      "outputs": [],
      "source": [
        "result"
      ],
      "id": "z-aqZR21d8RB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHR8XQsnOOmU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10)) \n",
        "plt.scatter(result[\"dim_1\"], result[\"dim_2\"], s = 5)"
      ],
      "id": "SHR8XQsnOOmU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8sYDYTTlPeh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = Axes3D(fig)\n",
        "ax.scatter(result[\"dim_1\"], result[\"dim_2\"], result['dim_3'], c ='blue', s = 1)\n",
        "\n",
        "plt.show()"
      ],
      "id": "E8sYDYTTlPeh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax6JaSFBTcw7"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "\n",
        "clusters = range(2,50)\n",
        "sc_scores = []\n",
        "for k in tqdm(clusters):\n",
        "  kmeans_model = KMeans(n_clusters=k).fit(result)\n",
        "  sc_score = metrics.silhouette_score(result, kmeans_model.labels_,sample_size=10000, metric='euclidean')\n",
        "  sc_scores.append(sc_score)\n",
        "print(sc_scores)\n",
        "best_clusters = sc_scores.index(max(sc_scores))+2\n",
        "print(best_clusters)"
      ],
      "id": "Ax6JaSFBTcw7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9NVd6MdUEjx"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(clusters, sc_scores, )\n",
        "plt.xlabel('Clusters',fontsize=18)\n",
        "plt.ylabel('Silhouette Coefficient Score',fontsize=18)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.show()"
      ],
      "id": "w9NVd6MdUEjx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MwrvzLSP33Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=best_clusters)\n",
        "kmeans.fit(result)\n",
        "\n",
        "plt.rcParams['font.size'] = 14\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.title('Segmented data')\n",
        "plt.scatter(result['dim_1'], result['dim_2'], c = kmeans.predict(result), s = 5)"
      ],
      "id": "9MwrvzLSP33Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnqZhFxW1bH-"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = Axes3D(fig)\n",
        "ax.scatter(result[\"dim_1\"], result[\"dim_2\"], result['dim_3'], c = kmeans.predict(result), s = 1)\n",
        "\n",
        "plt.show()"
      ],
      "id": "WnqZhFxW1bH-"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}