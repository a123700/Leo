{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a123700/Leo/blob/master/Next_Word_Prediction_with_BI_LSTM_and_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiEhZ7sfODHZ"
      },
      "outputs": [],
      "source": [
        "api_token = {\"username\":\"srhgccc\",\"key\":\"41c36ccc1ee7bc07f70e459ccbf7df7c\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        " \n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    os.makedirs(\"/root/.kaggle\")\n",
        " \n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        " \n",
        "if not os.path.exists(\"/kaggle\"):\n",
        "    os.makedirs(\"/kaggle\")\n",
        "os.chdir('/kaggle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTY3L1x0OD4m"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d hsankesara/medium-articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66vHOZaKOHSc"
      },
      "outputs": [],
      "source": [
        "!unzip medium-articles.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMlpEjMPN8HB"
      },
      "source": [
        "<a name=\"ilp\"></a>\n",
        "# Import necessary libraries and packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfEry9O1N8HC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Ao6dgbN8HE"
      },
      "source": [
        "<a name=\"di\"></a>\n",
        "# Dataset information\n",
        "\n",
        "**Import Medium-articles-dataset:**\n",
        "\n",
        "This dataset contains information about randomly chosen medium articles published in 2019 from these 7 publications:\n",
        "\n",
        "- Towards Data Science\n",
        "- UX Collective\n",
        "- The Startup\n",
        "- The Writing Cooperative\n",
        "- Data Driven Investor\n",
        "- Better Humans\n",
        "- Better Marketing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR_UnIITN8HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "82d352b1-af85-451b-ea79-82f82c73149b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             author claps  reading_time  \\\n",
              "0        Justin Lee  8.3K            11   \n",
              "1       Conor Dewey  1.4K             7   \n",
              "2  William Koehrsen  2.8K            11   \n",
              "3      Gant Laborde  1.3K             7   \n",
              "4  Emmanuel Ameisen   935            11   \n",
              "\n",
              "                                                link  \\\n",
              "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
              "1  https://towardsdatascience.com/python-for-data...   \n",
              "2  https://towardsdatascience.com/automated-featu...   \n",
              "3  https://medium.freecodecamp.org/machine-learni...   \n",
              "4  https://blog.insightdatascience.com/reinforcem...   \n",
              "\n",
              "                                               title  \\\n",
              "0  Chatbots were the next big thing: what happene...   \n",
              "1  Python for Data Science: 8 Concepts You May Ha...   \n",
              "2  Automated Feature Engineering in Python – Towa...   \n",
              "3  Machine Learning: how to go from Zero to Hero ...   \n",
              "4  Reinforcement Learning from scratch – Insight ...   \n",
              "\n",
              "                                                text  \n",
              "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
              "1  If you’ve ever found yourself looking up the s...  \n",
              "2  Machine learning is increasingly moving from h...  \n",
              "3  If your understanding of A.I. and Machine Lear...  \n",
              "4  Want to learn about applied Artificial Intelli...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7b24589-5301-488c-97ba-71e96390673f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>claps</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>link</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Justin Lee</td>\n",
              "      <td>8.3K</td>\n",
              "      <td>11</td>\n",
              "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
              "      <td>Chatbots were the next big thing: what happene...</td>\n",
              "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Conor Dewey</td>\n",
              "      <td>1.4K</td>\n",
              "      <td>7</td>\n",
              "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
              "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
              "      <td>If you’ve ever found yourself looking up the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>William Koehrsen</td>\n",
              "      <td>2.8K</td>\n",
              "      <td>11</td>\n",
              "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
              "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
              "      <td>Machine learning is increasingly moving from h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gant Laborde</td>\n",
              "      <td>1.3K</td>\n",
              "      <td>7</td>\n",
              "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
              "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
              "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emmanuel Ameisen</td>\n",
              "      <td>935</td>\n",
              "      <td>11</td>\n",
              "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
              "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
              "      <td>Want to learn about applied Artificial Intelli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7b24589-5301-488c-97ba-71e96390673f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7b24589-5301-488c-97ba-71e96390673f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7b24589-5301-488c-97ba-71e96390673f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "medium_data = pd.read_csv('articles.csv')\n",
        "medium_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYJkWBizN8HI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v34-MNyUN8HI"
      },
      "source": [
        "Here, we have a **10 different fields and 6508 records** but we will only use **title field** for predicting next word. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHUSqEBTN8HJ",
        "outputId": "65d22c24-0cee-4528-8aac-48877744236d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records:  337\n",
            "Number of fields:  6\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of records: \", medium_data.shape[0])\n",
        "print(\"Number of fields: \", medium_data.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09olPczrN8HJ"
      },
      "source": [
        "<a name=\"preprocess\"></a>\n",
        "# Display titles of various articles  and preprocess them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-1KsPRbN8HL"
      },
      "source": [
        "<a name=\"remv\"></a>\n",
        "#### Removing unwanted characters and words in titles\n",
        "\n",
        "Looking at titles, we can see there are some of unwanted characters and words in it which can not be useful for us to predict infact it might decrease our model accuracy so we have to remove it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Remove non-alphabetic characters (Data Cleaning)\n",
        "def text_strip(row):\n",
        "  row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
        "  row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
        "  row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove _ if it occurs more than one time consecutively\n",
        "  row = re.sub(\"(__+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove - if it occurs more than one time consecutively\n",
        "  row = re.sub(\"(--+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove ~ if it occurs more than one time consecutively\n",
        "  row = re.sub(\"(~~+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove + if it occurs more than one time consecutively\n",
        "  row = re.sub(\"(\\+\\++)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove . if it occurs more than one time consecutively\n",
        "  row = re.sub(\"(\\.\\.+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove the characters - <>()|&©ø\"',;?~*!\n",
        "  row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove mailto:\n",
        "  row = re.sub(\"(mailto:)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove \\x9* in text\n",
        "  row = re.sub(r\"(\\\\x9\\d)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Replace INC nums to INC_NUM\n",
        "  row = re.sub(\"([iI][nN][cC]\\d+)\", \"INC_NUM\", str(row)).lower()\n",
        "\n",
        "        # Replace CM# and CHG# to CM_NUM\n",
        "  row = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", \"CM_NUM\", str(row)).lower()\n",
        "\n",
        "        # Remove punctuations at the end of a word\n",
        "  row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
        "  row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
        "  row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Replace any url to only the domain name\n",
        "  try:\n",
        "    url = re.search(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", str(row))\n",
        "    repl_url = url.group(3)\n",
        "    row = re.sub(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", repl_url, str(row))\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "        # Remove multiple spaces\n",
        "  row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
        "\n",
        "        # Remove the single character hanging between any two spaces\n",
        "  row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
        "\n",
        "  return row"
      ],
      "metadata": {
        "id": "uPWFaBICwJ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZjCXjX0N8HL"
      },
      "outputs": [],
      "source": [
        "medium_data['text'] = medium_data['text'].apply(lambda x: 'sos '+x+' eos')\n",
        "\n",
        "medium_data['text'] = medium_data['text'].apply(lambda x: text_strip(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "-Lfwf657mKWM",
        "outputId": "d4b12518-4270-405b-8949-a3670e1f13c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    author claps  reading_time  \\\n",
              "258            Greg Gascon   368             6   \n",
              "291         Arthur Juliani    9K             6   \n",
              "182    Christian Hernandez   364             7   \n",
              "300    Milo Spencer-Harper  2.2K             3   \n",
              "76   Blaise Aguera y Arcas  8.7K            15   \n",
              "\n",
              "                                                  link  \\\n",
              "258  https://medium.com/startup-grind/how-invisible...   \n",
              "291  https://medium.com/emergent-future/simple-rein...   \n",
              "182  https://medium.com/crossing-the-pond/into-the-...   \n",
              "300  https://medium.com/technology-invention-and-mo...   \n",
              "76   https://medium.com/@blaisea/do-algorithms-reve...   \n",
              "\n",
              "                                                 title  \\\n",
              "258  How Invisible Interfaces are going to transfor...   \n",
              "291  Simple Reinforcement Learning with Tensorflow ...   \n",
              "182  Into the Age of Context – Crossing the Pond – ...   \n",
              "300  How to build a multi-layered neural network in...   \n",
              "76   Do algorithms reveal sexual orientation or jus...   \n",
              "\n",
              "                                                  text  \n",
              "258  sos in the mid-nineties computer scientist at ...  \n",
              "291  sos for this tutorial in my reinforcement lear...  \n",
              "182  sos spent most of my early career proclaiming ...  \n",
              "300  sos in my last blog post thanks to an excellen...  \n",
              "76   sos by blaise agüera arcas alexander todorov ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2efb5f52-9402-4125-a6e9-009990cba425\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>claps</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>link</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>Greg Gascon</td>\n",
              "      <td>368</td>\n",
              "      <td>6</td>\n",
              "      <td>https://medium.com/startup-grind/how-invisible...</td>\n",
              "      <td>How Invisible Interfaces are going to transfor...</td>\n",
              "      <td>sos in the mid-nineties computer scientist at ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>Arthur Juliani</td>\n",
              "      <td>9K</td>\n",
              "      <td>6</td>\n",
              "      <td>https://medium.com/emergent-future/simple-rein...</td>\n",
              "      <td>Simple Reinforcement Learning with Tensorflow ...</td>\n",
              "      <td>sos for this tutorial in my reinforcement lear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>Christian Hernandez</td>\n",
              "      <td>364</td>\n",
              "      <td>7</td>\n",
              "      <td>https://medium.com/crossing-the-pond/into-the-...</td>\n",
              "      <td>Into the Age of Context – Crossing the Pond – ...</td>\n",
              "      <td>sos spent most of my early career proclaiming ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>Milo Spencer-Harper</td>\n",
              "      <td>2.2K</td>\n",
              "      <td>3</td>\n",
              "      <td>https://medium.com/technology-invention-and-mo...</td>\n",
              "      <td>How to build a multi-layered neural network in...</td>\n",
              "      <td>sos in my last blog post thanks to an excellen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Blaise Aguera y Arcas</td>\n",
              "      <td>8.7K</td>\n",
              "      <td>15</td>\n",
              "      <td>https://medium.com/@blaisea/do-algorithms-reve...</td>\n",
              "      <td>Do algorithms reveal sexual orientation or jus...</td>\n",
              "      <td>sos by blaise agüera arcas alexander todorov ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2efb5f52-9402-4125-a6e9-009990cba425')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2efb5f52-9402-4125-a6e9-009990cba425 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2efb5f52-9402-4125-a6e9-009990cba425');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8JmdUB4zwpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9412a4e3-1875-47ce-cde1-79ba2966a46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "337\n"
          ]
        }
      ],
      "source": [
        "data = medium_data['text'].tolist()\n",
        "\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TybPo8b8N8HN"
      },
      "source": [
        "<a name=\"token\"></a>\n",
        "#### Tokenization\n",
        "\n",
        "Tokenization is the process in which we provide an unique id to all the words and make a word index or we can say vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrcWcSdzN8HO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjs7Lm1PN8HO"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(oov_token='<oov>') # For those words which are not found in word_index\n",
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 500  # Only consider the first 500 words of each movie review"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of words: \", total_words)\n",
        "print(\"Word: ID\")\n",
        "print(\"------------\")\n",
        "print(\"<oov>: \", tokenizer.word_index['<oov>'])\n",
        "print(\"machine: \", tokenizer.word_index['machine'])\n",
        "print(\"request: \", tokenizer.word_index['request'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf2QSb-kluDt",
        "outputId": "25824e06-8b20-4ba1-e745-da0aa94d8dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words:  21968\n",
            "Word: ID\n",
            "------------\n",
            "<oov>:  1\n",
            "machine:  44\n",
            "request:  2975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROjfOhJQN8HR"
      },
      "source": [
        "<a name=\"xy\"></a>\n",
        "# Prepare features and labels\n",
        "\n",
        "Here, we consider **last element of all sequences as a label**.Then,\n",
        "We need to perform **onehot encoding on labels corresponding to total_words.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7OYD5NnN8HP",
        "outputId": "b380e416-53ef-42fa-c89b-c0bc35ffb85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 337/337 [00:03<00:00, 86.52it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total input sequences:  542198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "xs = []\n",
        "ys = []\n",
        "forward_words = 200\n",
        "\n",
        "for line in tqdm(data):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    \n",
        "    for i in range(len(token_list)-forward_words):\n",
        "        n_gram_sequence = token_list[i:i+forward_words]\n",
        "        labels = token_list[i+forward_words]\n",
        "        xs.append(n_gram_sequence)\n",
        "        ys.append(labels)\n",
        "\n",
        "print(\"\\nTotal input sequences: \", len(xs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array(xs)\n",
        "ys = np.array(ys)"
      ],
      "metadata": {
        "id": "04e50pd9pLAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmQPANxVN8HS"
      },
      "source": [
        "<a name=\"train\"></a>\n",
        "# Bi- LSTM Neural Network Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG9JdJfdSGO5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtpHDH2IN8HT"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=forward_words))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences = True)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Bidirectional(LSTM(16, return_sequences = True)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Bidirectional(LSTM(8, return_sequences = False)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(xs, ys, random_state=777, train_size=0.9)"
      ],
      "metadata": {
        "id": "R7hVFCK8Ol0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "1ETwJ1D7Ol0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "EjFHJEazOl0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "metadata": {
        "id": "zuoWCnVPOl0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "vjrxsnRfQGcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# red_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=10,verbose=0,factor=0.1)\n",
        "# callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "# history = model.fit(xs, ys, epochs=50, verbose=1, callbacks = [callbacks, red_lr], batch_size=1024, validation_split=0.1)"
      ],
      "metadata": {
        "id": "Nvub4ZlJn967"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--W6QPjBp6Lb"
      },
      "source": [
        "<a name=\"acc\"></a>\n",
        "## Plotting Bi- LSTM model accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-tN8MZip6Lc"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model Loss')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend(['train', 'test'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aToXtVZYp6Lc"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('Model Accuracy')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend(['train', 'test'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oiMo-awp6Ld"
      },
      "source": [
        "<a name=\"new\"></a>\n",
        "## Predicting next word of title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mck845dGp6Ld"
      },
      "outputs": [],
      "source": [
        "seed_text = \"Where\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in tqdm(range(next_words)):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=forward_words, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted = np.argmax(predicted, axis=1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmzFqIMHYIEq"
      },
      "source": [
        "<a name=\"train\"></a>\n",
        "# Transformer Neural Network Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1BrzXmlqAOM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HEdzcsSSA6c"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9g5l14RSJur"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izBi2FXfSNmi"
      },
      "outputs": [],
      "source": [
        "embed_dim = 200  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(xs.shape[1],))\n",
        "embedding_layer = TokenAndPositionEmbedding(forward_words, total_words, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "outputs = layers.Dense(total_words, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps1Q3OuASyT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d07377-fb33-4cf4-e74e-f3ed894e45f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 200, 200)         4433600   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_block (Transfor  (None, 200, 200)         348064    \n",
            " merBlock)                                                       \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 200)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                4020      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10984)             230664    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 21968)             241318480 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246,334,828\n",
            "Trainable params: 246,334,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(xs, ys, random_state=777, train_size=0.9)"
      ],
      "metadata": {
        "id": "0L1aT2GaMVD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "iRoruNYIM4kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "rqEehoyaL5hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "metadata": {
        "id": "C0_zUryOL5A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "il-dY8DuMz2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84IJghYzSzto"
      },
      "outputs": [],
      "source": [
        "# import keras\n",
        "# from keras.callbacks import ReduceLROnPlateau\n",
        "# red_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=0,factor=0.1)\n",
        "# callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]\n",
        "\n",
        "# history = model.fit(xs, ys, batch_size=4096, epochs=100, validation_split = 0.15, callbacks = [callbacks, red_lr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLksuiIzN8HV"
      },
      "source": [
        "<a name=\"acc\"></a>\n",
        "## Plotting Transformer model accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON6kBBKrN8HV"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model Loss')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend(['train', 'test'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6ZZ7ZAYN8HW"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('Model Accuracy')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend(['train', 'test'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBJanR2qN8HX"
      },
      "source": [
        "<a name=\"new\"></a>\n",
        "## Predicting next word of title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfVPj_LaN8HY"
      },
      "outputs": [],
      "source": [
        "seed_text = \"Mechine learning is\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in tqdm(range(next_words)):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=forward_words, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted = np.argmax(predicted, axis=1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    if output_word == 'eos':\n",
        "      break\n",
        "    seed_text += \" \" + output_word\n",
        "print('\\n'+seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}