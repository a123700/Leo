{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a123700/Leo/blob/master/WGAN_with_Gradient_Penalty_and_Spectral_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Wasserstein Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HQfTSaa8UJ3"
      },
      "outputs": [],
      "source": [
        "api_token = {\"username\":\"srhgccc\",\"key\":\"41c36ccc1ee7bc07f70e459ccbf7df7c\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        " \n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    os.makedirs(\"/root/.kaggle\")\n",
        " \n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        " \n",
        "if not os.path.exists(\"/kaggle\"):\n",
        "    os.makedirs(\"/kaggle\")\n",
        "os.chdir('/kaggle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMtn0-S98XuR"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d karnikakapoor/art-portraits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktafggKot91L"
      },
      "outputs": [],
      "source": [
        "!unzip art-portraits.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzTlj4YdCip_"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-addons\n",
        "\n",
        "# To generate GIFs\n",
        "!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import concurrent.futures\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import SpectralNormalization, InstanceNormalization\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrQBQxgtEtbd"
      },
      "outputs": [],
      "source": [
        "def read_img(image):\n",
        "    img = tf.keras.preprocessing.image.load_img(image, color_mode='rgb', target_size=(img_size, img_size))\n",
        "    return img\n",
        "def prepare_dataset(namelist):\n",
        "    start = time.time()\n",
        "    imgs = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers = 16) as executor:\n",
        "        i = 0\n",
        "        for value in executor.map(read_img, namelist):\n",
        "            i+=1\n",
        "            print(\"\\rFetching: [{}/{}]\".format(i, len(namelist)), end=\"\", flush=True)\n",
        "            imgs.append(value)\n",
        "        imgs = np.stack(imgs)\n",
        "        imgs = tf.convert_to_tensor(imgs)\n",
        "    print(\"\\nExecution time: \",round(time.time() - start), \"s\")\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLRehrSD8d1u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "img_size = 64\n",
        "channels = 3\n",
        "train_paths = glob.glob('Portraits/*.jpg')\n",
        "\n",
        "images = prepare_dataset(train_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGNNEBZZk-dt"
      },
      "outputs": [],
      "source": [
        "_,ax = plt.subplots(5,5, figsize = (16, 16)) \n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        ax[i,j].imshow(images[5*i+j])\n",
        "        ax[i,j].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFC2ghIdiZYE"
      },
      "outputs": [],
      "source": [
        "train_images = images.reshape(-1, img_size, img_size, channels).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF6-4Xymrdom"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "latent_size = 16\n",
        "noise_dim = 3000\n",
        "\n",
        "img_shape = (img_size, img_size, channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yKCCQOoJ7cn"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Create the models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectral Normalization"
      ],
      "metadata": {
        "id": "nlZ5yf02EcmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralNorm1D(Constraint):\n",
        "    def __init__(self, output_neurons, power_iterations=1):\n",
        "\n",
        "        assert power_iterations>=1, \"The number of power iterations should be positive integer\"\n",
        "        self.Ip = power_iterations\n",
        "        u_init = tf.random_uniform_initializer()\n",
        "        self.u = tf.Variable(initial_value = u_init(shape=(1, output_neurons), dtype='float32'),\n",
        "                             trainable = False)\n",
        "\n",
        "    def __call__(self, w):\n",
        "\n",
        "        W_mat = tf.transpose(w, (1, 0))  # (i, o) => (o, i)\n",
        "\n",
        "        _u = self.u\n",
        "        _v = None\n",
        "\n",
        "        for _ in range(self.Ip):\n",
        "            _v = l2_norm(tf.matmul(_u, W_mat))\n",
        "            _u = l2_norm(tf.matmul(_v, W_mat, transpose_b=True))\n",
        "\n",
        "        sigma = tf.reduce_sum(tf.matmul(_u, W_mat) * _v)\n",
        "        sigma = tf.cond(sigma == 0, lambda: 1e-8, lambda: sigma)\n",
        "\n",
        "        self.u.assign(tf.keras.backend.in_train_phase(_u, self.u))\n",
        "        return w / sigma"
      ],
      "metadata": {
        "id": "2BUfDbpbDLXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralNorm2D(Constraint):\n",
        "    def __init__(self, output_neurons, power_iterations=1):\n",
        "\n",
        "        assert power_iterations>=1, \"The number of power iterations should be positive integer\"\n",
        "        self.Ip = power_iterations\n",
        "        u_init = tf.random_uniform_initializer()\n",
        "        self.u = tf.Variable(initial_value = u_init(shape=(1, output_neurons), dtype='float32'),\n",
        "                             trainable = False)\n",
        "\n",
        "    def __call__(self, w):\n",
        "\n",
        "        W_mat = tf.transpose(w, (3, 2, 0, 1))  # (h, w, i, o) => (o, i, h, w)\n",
        "        W_mat = tf.reshape(W_mat, [tf.shape(W_mat)[0], -1])  # (o, i * h * w)\n",
        "\n",
        "        _u = self.u\n",
        "        _v = None\n",
        "\n",
        "        for _ in range(self.Ip):\n",
        "            _v = l2_norm(tf.matmul(_u, W_mat))\n",
        "            _u = l2_norm(tf.matmul(_v, W_mat, transpose_b=True))\n",
        "\n",
        "        sigma = tf.reduce_sum(tf.matmul(_u, W_mat) * _v)\n",
        "        sigma = tf.cond(sigma == 0, lambda: 1e-8, lambda: sigma)\n",
        "\n",
        "        self.u.assign(tf.keras.backend.in_train_phase(_u, self.u))\n",
        "        return w / sigma"
      ],
      "metadata": {
        "id": "kPLnjzpYDPeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_norm(x):\n",
        "    return x / tf.sqrt(tf.reduce_sum(tf.square(x)) + 1e-8)"
      ],
      "metadata": {
        "id": "0QtoetgcEoKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### The Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bpTcDqoLWjY"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input = Input(shape=noise_dim)\n",
        "    x = Dense(8*img_size*img_size, activation=\"relu\")(input)\n",
        "    x = Reshape((img_size//8, img_size//8, -1))(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64*4, kernel_size=3, strides=1, padding=\"same\",\n",
        "                   use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x, training=1)\n",
        "    x = Conv2D(64*4, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5, )(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(64*4, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64*2, kernel_size=3, strides=1, padding=\"same\",\n",
        "               use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x, training=1)\n",
        "    x = Conv2D(64*2, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5, )(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(64*2, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64*1, kernel_size=3, strides=1, padding=\"same\",\n",
        "                   use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x,training=1)\n",
        "    x = Conv2D(64*1, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5, )(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(64*1, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=3, \n",
        "                  center=True, \n",
        "                  scale=True,\n",
        "                  beta_initializer=\"random_uniform\",\n",
        "                  gamma_initializer=\"random_uniform\")(x)\n",
        "    # x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x, training=1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(channels, kernel_size=3, strides=1, padding=\"same\", activation=\"tanh\",\n",
        "               use_bias=False,)(x)\n",
        "\n",
        "    model = Model(input, x)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWgG09LCSJl"
      },
      "source": [
        "Use the (as yet untrained) generator to create an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl7jcC7TdPTG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "generator = make_generator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L13IM-3FWyE"
      },
      "outputs": [],
      "source": [
        "noise = tf.random.normal([1, noise_dim])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow((generated_image[0, :, :, :]*127.5+127.5).astype(np.uint8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### The Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    input = Input(shape=img_shape)\n",
        "    x = Conv2D(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(64))(input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(128))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(256, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(256))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(256))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(256))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(512, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(512))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Conv2D(1, kernel_size=1, strides=1, padding=\"same\", use_bias=False, kernel_constraint=SpectralNorm2D(1))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=1, activation=None, kernel_constraint=SpectralNorm1D(1))(x) \n",
        "    \n",
        "    model = Model(input, x)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "outputs": [],
      "source": [
        "discriminator = make_discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6sslpsaFhro"
      },
      "outputs": [],
      "source": [
        "decision = discriminator(generated_image)\n",
        "print(decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss and optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Discriminator loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Generator loss\n",
        "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "The discriminator and the generator optimizers are different since you will train two networks separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT52Hmq_z2Uz"
      },
      "source": [
        "## Gradient Penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-ChqP07cjgk"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(batch_size, real_images, fake_images):\n",
        "        \"\"\"Calculates the gradient penalty.\n",
        "\n",
        "        This loss is calculated on an interpolated image\n",
        "        and added to the discriminator loss.\n",
        "        \"\"\"\n",
        "        # Get the interpolated image\n",
        "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "        diff = fake_images - real_images\n",
        "        interpolated = real_images + alpha * diff\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            # 1. Get the discriminator output for this interpolated image.\n",
        "            pred = discriminator(interpolated, training=True)\n",
        "\n",
        "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        # 3. Calculate the norm of the gradients.\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWtinsGDPJlV"
      },
      "source": [
        "### Save checkpoints\n",
        "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA1w-7s2POEy"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "num_examples_to_generate = 25\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, gp_weight=10.0):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "      gp = gradient_penalty(BATCH_SIZE, images, generated_images)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output) + gp_weight*gp\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, round(time.time()-start)))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(16, 16))\n",
        "\n",
        "  dim = int(num_examples_to_generate**0.5)\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(dim, dim, i+1)\n",
        "      plt.imshow((predictions[i, :, :, :]*127.5+127.5).astype(np.uint8))\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly3UN0SLLY2l"
      },
      "outputs": [],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfM4YcPVPkNO"
      },
      "source": [
        "Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhXsd0srPo8c"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "## Create a GIF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfO5wCdclHGL"
      },
      "outputs": [],
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "outputs": [],
      "source": [
        "display_image(EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "Use `imageio` to create an animated gif using the images saved during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "outputs": [],
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBwyU6t2Wf3g"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}